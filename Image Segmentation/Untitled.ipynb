{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  20  17]\n",
      " [ 68 206  61]\n",
      " [220 101  89]\n",
      " [194 141  10]\n",
      " [ 58  94 234]\n",
      " [169 177 102]\n",
      " [127  46  97]\n",
      " [  8  41 118]\n",
      " [128  79 242]\n",
      " [ 82  51 131]\n",
      " [247  87  14]\n",
      " [166 164  19]\n",
      " [230 248 147]\n",
      " [  9 176  31]\n",
      " [243  52  19]\n",
      " [170  29  66]\n",
      " [ 42 117 236]\n",
      " [200  32   9]\n",
      " [235  64 212]\n",
      " [ 13 158 117]\n",
      " [ 60 185   3]\n",
      " [198  79 192]\n",
      " [ 93  86 110]\n",
      " [137  17 230]\n",
      " [148 108 204]\n",
      " [235  20  81]\n",
      " [137 239 106]\n",
      " [ 45  53  38]\n",
      " [157 138 212]\n",
      " [ 69 223 151]\n",
      " [ 71   9 124]\n",
      " [ 68 200  25]\n",
      " [197 126 126]\n",
      " [  9  13  45]\n",
      " [236  64 146]\n",
      " [194 163   9]\n",
      " [117 109 123]\n",
      " [111   5 182]\n",
      " [217 221  31]\n",
      " [ 76 176  59]\n",
      " [ 13 166 201]\n",
      " [238 193 146]\n",
      " [187 200 126]\n",
      " [235 150  85]\n",
      " [154 200  29]\n",
      " [251 232 146]\n",
      " [ 84 183  83]\n",
      " [137 246 132]\n",
      " [115 168 180]\n",
      " [180 112 167]\n",
      " [150  22 254]\n",
      " [ 39 115  78]\n",
      " [ 80 119 240]\n",
      " [124  67 120]\n",
      " [240  72  72]\n",
      " [ 38  65  26]\n",
      " [253   6 106]\n",
      " [ 48  10 236]\n",
      " [ 32 247 172]\n",
      " [186 175 192]\n",
      " [169 225 100]\n",
      " [165  57 249]\n",
      " [  0  88 110]\n",
      " [ 34 163 233]\n",
      " [142 113 227]\n",
      " [211 176  42]\n",
      " [177 161 217]\n",
      " [253  28 229]\n",
      " [157 144 160]\n",
      " [209 127  90]\n",
      " [ 49 157 192]\n",
      " [221 199  27]\n",
      " [226   8 119]\n",
      " [196  62  69]\n",
      " [252  39 175]\n",
      " [ 99 247  38]\n",
      " [ 94  55 215]\n",
      " [ 95 192 219]\n",
      " [126 138 128]\n",
      " [245 138 252]]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-inblc7p7\\opencv\\modules\\imgproc\\src\\resize.cpp:4054: error: (-215:Assertion failed) inv_scale_x > 0 in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c59cd11a7d44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# Get the mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroi_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroi_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-inblc7p7\\opencv\\modules\\imgproc\\src\\resize.cpp:4054: error: (-215:Assertion failed) inv_scale_x > 0 in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# https://pysource.com/instance-segmentation-mask-rcnn-with-python-and-opencv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Loading Mask RCNN\n",
    "net = cv2.dnn.readNetFromTensorflow(\"dnn/frozen_inference_graph_coco.pb\",\"dnn/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\")\n",
    "\n",
    "# Generate random colors\n",
    "colors = np.random.randint(0, 255, (80, 3))\n",
    "\n",
    "print(colors)\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(\"car.jpg\") \n",
    "height, width, _ = img.shape\n",
    "\n",
    "# Create black image\n",
    "black_image = np.zeros((height, width, 3), np.uint8)\n",
    "black_image[:] = (100, 100, 0)\n",
    "\n",
    "# Detect objects\n",
    "blob = cv2.dnn.blobFromImage(img, swapRB=True)\n",
    "net.setInput(blob)\n",
    "\n",
    "boxes, masks = net.forward([\"detection_out_final\", \"detection_masks\"])\n",
    "detection_count = boxes.shape[2]\n",
    "\n",
    "for i in range(detection_count):\n",
    "    box = boxes[0, 0, i]\n",
    "    class_id = box[1]\n",
    "    score = box[2]\n",
    "    if score < 0.5:\n",
    "        continue \n",
    "\n",
    "# Get box Coordinates\n",
    "x = int(box[3] * width)\n",
    "y = int(box[4] * height)\n",
    "x2 = int(box[5] * width)\n",
    "y2 = int(box[6] * height)\n",
    "\n",
    "roi = black_image[y: y2, x: x2]\n",
    "roi_height, roi_width, _ = roi.shape\n",
    "\n",
    "# Get the mask\n",
    "mask = masks[i, int(class_id)]\n",
    "mask = cv2.resize(mask, (roi_width, roi_height))\n",
    "_, mask = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.rectangle(img, (x, y), (x2, y2), (255, 0, 0), 3)\n",
    "\n",
    "# Get mask coordinates\n",
    "contours, _ = cv2.findContours(np.array(mask, np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "color = colors[int(class_id)]\n",
    "for cnt in contours:\n",
    "    cv2.fillPoly(roi, [cnt], (int(color[0]), int(color[1]), int(color[2])))\n",
    "\n",
    "# cv2.imshow(\"roi\", roi)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Black image\", black_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
